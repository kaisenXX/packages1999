import os
import glob
import random
import numpy as np
from PIL import Image, ImageFilter
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split
import torchvision.transforms as T
import torchvision.models as models

# =====================
# Config
# =====================
DATA_DIR = "./aircraft_crops"
PRETRAINED_VGG = "./pretrained/vgg19-dcbb9e9d.pth"
CKPT_DIR = "./checkpoints"
LOG_DIR = "./sr_logs"
RESULT_DIR = "./sr_results"
HR_SIZE = 100
SCALE = 4
BATCH_SIZE = 8
EPOCHS = 5
LR = 1e-4
VAL_SPLIT = 0.2
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# =====================
# Dataset
# =====================
class AircraftDataset(Dataset):
    def __init__(self, root, hr_size=HR_SIZE, scale=SCALE, use_degrade=False):
        self.files = sorted(
            glob.glob(os.path.join(root, "*.jpeg")) +
            glob.glob(os.path.join(root, "*.jpg")) +
            glob.glob(os.path.join(root, "*.png"))
        )
        self.hr_size = hr_size
        self.scale = scale
        self.use_degrade = use_degrade

        self.hr_transform = T.Compose([
            T.Resize((hr_size, hr_size), interpolation=Image.BICUBIC),
            T.ToTensor()
        ])
        self.lr_bicubic = T.Compose([
            T.Resize((hr_size // scale, hr_size // scale), interpolation=Image.BICUBIC),
            T.ToTensor()
        ])

    def degrade(self, hr_tensor):
        pil_hr = T.ToPILImage()(hr_tensor)
        lr_w = self.hr_size // self.scale
        lr_h = self.hr_size // self.scale
        pil_lr = pil_hr.resize((lr_w, lr_h), resample=Image.BICUBIC)
        if random.random() < 0.5:
            pil_lr = pil_lr.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.2, 1.2)))
        lr_tensor = T.ToTensor()(pil_lr)
        if random.random() < 0.5:
            noise = torch.randn_like(lr_tensor) * 0.05
            lr_tensor = torch.clamp(lr_tensor + noise, 0.0, 1.0)
        return lr_tensor

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        img = Image.open(self.files[idx]).convert("RGB")
        hr = self.hr_transform(img)
        if self.use_degrade:
            lr = self.degrade(hr)
        else:
            lr = self.lr_bicubic(img)
        return lr, hr

# =====================
# Model
# =====================
class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv2d(channels, channels, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(channels, channels, 3, padding=1)
        )
    def forward(self, x):
        return x + 0.1 * self.block(x)

class SRNet(nn.Module):
    def __init__(self, num_residuals=16):
        super().__init__()
        self.entry = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU(inplace=True)
        )
        self.res_blocks = nn.Sequential(*[ResidualBlock(64) for _ in range(num_residuals)])
        self.upsample2 = nn.Sequential(
            nn.Conv2d(64, 256, 3, padding=1),
            nn.PixelShuffle(2),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU(inplace=True)
        )
        self.exit2 = nn.Conv2d(64, 3, 3, padding=1)
        self.upsample4 = nn.Sequential(
            nn.Conv2d(64, 256, 3, padding=1),
            nn.PixelShuffle(2),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU(inplace=True)
        )
        self.exit4 = nn.Conv2d(64, 3, 3, padding=1)

    def forward(self, x):
        feat = self.entry(x)
        feat = self.res_blocks(feat)
        feat2 = self.upsample2(feat)
        out2 = self.exit2(feat2)
        feat4 = self.upsample4(feat2)
        out4 = self.exit4(feat4)
        return out2, out4

# =====================
# Perceptual Loss
# =====================
class VGGPerceptualLoss(nn.Module):
    def __init__(self, vgg_path):
        super().__init__()
        vgg19 = models.vgg19()
        vgg19.load_state_dict(torch.load(vgg_path))
        features = list(vgg19.features)[:36]
        self.vgg = nn.Sequential(*features).eval()
        for p in self.vgg.parameters():
            p.requires_grad = False

    def forward(self, sr, hr):
        f_sr = self.vgg(sr)
        f_hr = self.vgg(hr)
        return F.l1_loss(f_sr, f_hr)

# =====================
# Utils
# =====================
def save_image_grid(lr, sr2, sr4, hr, epoch, folder=LOG_DIR):
    os.makedirs(folder, exist_ok=True)
    H, W = hr.shape[-2], hr.shape[-1]
    lr_up = F.interpolate(lr, size=(H, W), mode="bicubic", align_corners=False)
    sr2_up = F.interpolate(sr2, size=(H, W), mode="bicubic", align_corners=False)
    grid = torch.cat([lr_up[0], sr2_up[0], sr4[0], hr[0]], dim=-1)
    grid = (grid.clamp(0, 1).permute(1,2,0).cpu().numpy() * 255).astype(np.uint8)
    Image.fromarray(grid).save(os.path.join(folder, f"epoch_{epoch:04d}.jpeg"))

def sobel_edges(x):
    x_gray = torch.mean(x, dim=1, keepdim=True)
    sobel_x = torch.tensor([[-1,0,1],[-2,0,2],[-1,0,1]],dtype=torch.float32,device=x.device).unsqueeze(0).unsqueeze(0)
    sobel_y = torch.tensor([[-1,-2,-1],[0,0,0],[1,2,1]],dtype=torch.float32,device=x.device).unsqueeze(0).unsqueeze(0)
    grad_x = F.conv2d(x_gray, sobel_x, padding=1)
    grad_y = F.conv2d(x_gray, sobel_y, padding=1)
    return torch.sqrt(grad_x**2 + grad_y**2 + 1e-6)

def laplacian_edges(x):
    x_gray = torch.mean(x, dim=1, keepdim=True)
    lap_kernel = torch.tensor([[0,1,0],[1,-4,1],[0,1,0]],dtype=torch.float32,device=x.device).unsqueeze(0).unsqueeze(0)
    return F.conv2d(x_gray, lap_kernel, padding=1)

# =====================
# Training function
# =====================
def train(stage=1):
    device = DEVICE
    use_degrade = (stage==2)
    dataset = AircraftDataset(DATA_DIR, hr_size=HR_SIZE, scale=SCALE, use_degrade=use_degrade)
    n_total = len(dataset)
    n_val = max(1,int(n_total*VAL_SPLIT))
    n_train = n_total - n_val
    train_ds, val_ds = random_split(dataset, [n_train, n_val])
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

    model = SRNet().to(device)
    optimizer = optim.Adam(model.parameters(), lr=LR)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)
    vgg_loss_fn = VGGPerceptualLoss(PRETRAINED_VGG).to(device)
    l1 = nn.L1Loss()

    os.makedirs(CKPT_DIR, exist_ok=True)
    start_epoch = 0

    if stage == 1:
        ckpts = sorted(glob.glob(os.path.join(CKPT_DIR, "clean_ckpt_*.pth")))
        if ckpts:
            latest = ckpts[-1]
            ckpt = torch.load(latest, map_location=device)
            model.load_state_dict(ckpt["model_state"])
            optimizer.load_state_dict(ckpt["optim_state"])
            scheduler.load_state_dict(ckpt["sched_state"])
            start_epoch = ckpt["epoch"] + 1
            print(f"[INFO] Stage 1: Resuming from {latest}, epoch {ckpt['epoch']}")
        else:
            print("[INFO] Stage 1: Starting fresh training.")
    else:
        # Stage 2: load last stage 1 checkpoint
        ckpts_stage1 = sorted(glob.glob(os.path.join(CKPT_DIR, "clean_ckpt_*.pth")))
        if ckpts_stage1:
            latest_stage1 = ckpts_stage1[-1]
            ckpt = torch.load(latest_stage1, map_location=device)
            model.load_state_dict(ckpt["model_state"])
            optimizer.load_state_dict(ckpt["optim_state"])
            scheduler.load_state_dict(ckpt["sched_state"])
            start_epoch = 0
            print(f"[INFO] Stage 2: Starting from stage 1 checkpoint {latest_stage1}")
        else:
            print("[INFO] Stage 2: No stage 1 checkpoint found, starting fresh.")

    for epoch in range(start_epoch, EPOCHS):
        model.train()
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}")
        for lr_img, hr_img in pbar:
            lr_img, hr_img = lr_img.to(device), hr_img.to(device)
            sr2, sr4 = model(lr_img)
            hr_half = F.interpolate(hr_img, scale_factor=0.5, mode="bicubic", align_corners=False)

            loss_l1 = l1(sr2, hr_half) + l1(sr4, hr_img)
            loss_vgg = vgg_loss_fn(sr4, hr_img)

            edges_sr_sobel = sobel_edges(sr4)
            edges_hr_sobel = sobel_edges(hr_img)
            edges_sr_lap = laplacian_edges(sr4)
            edges_hr_lap = laplacian_edges(hr_img)
            loss_edge = F.l1_loss(edges_sr_sobel, edges_hr_sobel) + F.l1_loss(edges_sr_lap, edges_hr_lap)

            loss = 0.5*loss_l1 + 1*loss_vgg + 0.7*loss_edge

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            pbar.set_postfix({"loss": f"{loss.item():.4f}"})

        # Validation preview
        model.eval()
        with torch.no_grad():
            try:
                lr_v, hr_v = next(iter(val_loader))
                lr_v, hr_v = lr_v.to(device), hr_v.to(device)
                sr2_v, sr4_v = model(lr_v)
                folder = LOG_DIR if stage==1 else LOG_DIR+"/degrade_stage2"
                save_image_grid(lr_v, sr2_v, sr4_v, hr_v, epoch+1, folder)
            except StopIteration:
                pass

        # Save checkpoint
        ckpt_name = "clean_ckpt" if stage==1 else "degrade_ckpt"
        ckpt_path = os.path.join(CKPT_DIR, f"{ckpt_name}_epoch{epoch+1:04d}.pth")
        torch.save({
            "epoch": epoch,
            "model_state": model.state_dict(),
            "optim_state": optimizer.state_dict(),
            "sched_state": scheduler.state_dict()
        }, ckpt_path)
        print(f"[INFO] Saved checkpoint: {ckpt_path}")

# =====================
# Inference
# =====================
def infer(img_path, ckpt_path, which="4x"):
    device = DEVICE
    model = SRNet().to(device)
    ckpt = torch.load(ckpt_path, map_location=device)
    model.load_state_dict(ckpt["model_state"])
    model.eval()
    img = Image.open(img_path).convert("RGB")
    lr = T.ToTensor()(img).unsqueeze(0).to(device)
    with torch.no_grad():
        sr2, sr4 = model(lr)
        sr = sr2 if which=="2x" else sr4
    sr = sr.clamp(0,1)[0].permute(1,2,0).cpu().numpy()
    sr = (sr*255).astype(np.uint8)
    os.makedirs(RESULT_DIR, exist_ok=True)
    out_path = os.path.join(RESULT_DIR, f"sr_{which}.jpg")
    Image.fromarray(sr).save(out_path)
    print(f"[INFO] Saved: {out_path}")

# =====================
# Run
# =====================
if __name__ == "__main__":
    # Stage 1: clean training
    train(stage=1)
    # Stage 2: degraded training (starts from stage 1 checkpoint)
    train(stage=2)

    # Example inference after stage 2:
    # infer("./aircraft_crops/some_crop.jpeg", "./checkpoints/degrade_ckpt_epoch0005.pth", which="4x")
